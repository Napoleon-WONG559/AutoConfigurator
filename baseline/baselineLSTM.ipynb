{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install keras_preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:04:23.807306Z","iopub.status.busy":"2023-05-16T03:04:23.806909Z","iopub.status.idle":"2023-05-16T03:04:24.938557Z","shell.execute_reply":"2023-05-16T03:04:24.937514Z","shell.execute_reply.started":"2023-05-16T03:04:23.807272Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:04:31.537042Z","iopub.status.busy":"2023-05-16T03:04:31.536153Z","iopub.status.idle":"2023-05-16T03:04:31.552332Z","shell.execute_reply":"2023-05-16T03:04:31.551193Z","shell.execute_reply.started":"2023-05-16T03:04:31.537001Z"},"trusted":true},"outputs":[],"source":["import argparse\n","\n","#-----------------------------parser-----------------------------\n","class MyArgs:\n","    def __init__(self):\n","        self.epochs=5\n","        self.learning_rate=1e-5\n","        self.hidden_dim=128\n","        self.lstm_layers=1\n","        self.batch_size=64\n","        self.test_size=0.1\n","        self.max_len=512\n","        self.max_words=28996"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:31:13.064280Z","iopub.status.busy":"2023-05-16T03:31:13.063528Z","iopub.status.idle":"2023-05-16T03:31:13.080991Z","shell.execute_reply":"2023-05-16T03:31:13.079927Z","shell.execute_reply.started":"2023-05-16T03:31:13.064236Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","#from keras.preprocessing import sequence\n","from keras_preprocessing import sequence\n","from keras.preprocessing.text import Tokenizer\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n","class Preprocessing:\n","\t\n","\tdef __init__(self, args):\n","\t\tself.data = '/kaggle/input/reviewdata/review_cpu_label_map.csv'\n","\t\tself.max_len = args.max_len\n","\t\tself.max_words = args.max_words\n","\t\tself.test_size = args.test_size\n","\t\t\n","\tdef load_data(self):\n","\t\tdf = pd.read_csv(self.data)\n","\t\tdf.drop(['index'], axis=1, inplace=True)\n","\t\t\n","\t\tX = df['review'].values\n","\t\tY = df['cpu_label'].values\n","\t\t\n","\t\tself.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, Y, test_size=self.test_size)\n","\t\t\n","\tdef prepare_tokens(self):\n","\t\tself.tokens = Tokenizer(num_words=self.max_words)\n","\t\tself.tokens.fit_on_texts(self.x_train)\n","\n","\tdef sequence_to_token(self, x):\n","\t\tsequences = self.tokens.texts_to_sequences(x)\n","\t\treturn sequence.pad_sequences(sequences, maxlen=self.max_len)\n","\n","class PreprocessingFT:\n","\t\n","\tdef __init__(self, args):\n","\t\tself.data = '/kaggle/input/needdata/need_cpu_label_map.csv'\n","\t\tself.max_len = args.max_len\n","\t\tself.max_words = args.max_words\n","\t\tself.test_size = 0.5\n","\t\t\n","\tdef load_data(self):\n","\t\tdf = pd.read_csv(self.data)\n","\t\tdf.drop(['index'], axis=1, inplace=True)\n","\t\t\n","\t\tX = df['need'].values\n","\t\tY = df['cpu_label'].values\n","\t\t\n","\t\tself.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, Y, test_size=self.test_size)\n","\t\t\n","\tdef prepare_tokens(self):\n","\t\tself.tokens = Tokenizer(num_words=self.max_words)\n","\t\tself.tokens.fit_on_texts(self.x_train)\n","\n","\tdef sequence_to_token(self, x):\n","\t\tsequences = self.tokens.texts_to_sequences(x)\n","\t\treturn sequence.pad_sequences(sequences, maxlen=self.max_len)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:31:35.752261Z","iopub.status.busy":"2023-05-16T03:31:35.751682Z","iopub.status.idle":"2023-05-16T03:31:35.767902Z","shell.execute_reply":"2023-05-16T03:31:35.766837Z","shell.execute_reply.started":"2023-05-16T03:31:35.752220Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class TweetClassifier(nn.ModuleList):\n","\n","\tdef __init__(self, args):\n","\t\tsuper(TweetClassifier, self).__init__()\n","\t\t\n","\t\tself.batch_size = args.batch_size\n","\t\tself.hidden_dim = args.hidden_dim\n","\t\tself.LSTM_layers = args.lstm_layers\n","\t\tself.input_size = args.max_words # embedding dimention\n","\t\t\n","\t\tself.dropout = nn.Dropout(0.5)\n","\t\tself.embedding = nn.Embedding(self.input_size, self.hidden_dim, padding_idx=0)\n","\t\tself.lstm = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=self.LSTM_layers, batch_first=True)\n","\t\tself.fc1 = nn.Linear(in_features=self.hidden_dim, out_features=257)\n","\t\t#self.fc2 = nn.Linear(257, 1)\n","\t\t#change output_channels according to label size\n","\t\tself.fc2 = nn.Linear(257, 4)#label size\n","\t\tself.softmax=nn.LogSoftmax(dim=1)\n","\t\t\n","\tdef forward(self, x):\n","\t\n","\t\th = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim),device=x.device)\n","\t\tc = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim),device=x.device)\n","\t\t\n","\t\ttorch.nn.init.xavier_normal_(h)\n","\t\ttorch.nn.init.xavier_normal_(c)\n","\n","\t\tout = self.embedding(x)\n","\t\tout, (hidden, cell) = self.lstm(out, (h,c))\n","\t\tout = self.dropout(out)\n","\t\tout = torch.relu_(self.fc1(out[:,-1,:]))\n","\t\tout = self.dropout(out)\n","\t\t#out = torch.sigmoid(self.fc2(out))\n","\t\tout = self.softmax(self.fc2(out))\n","\n","\t\treturn out"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:31:38.121607Z","iopub.status.busy":"2023-05-16T03:31:38.121155Z","iopub.status.idle":"2023-05-16T03:31:38.171625Z","shell.execute_reply":"2023-05-16T03:31:38.170309Z","shell.execute_reply.started":"2023-05-16T03:31:38.121570Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","import csv\n","\n","class DatasetMaper(Dataset):\n","\t'''\n","\tHandles batches of dataset\n","\t'''\n","\tdef __init__(self, x, y):\n","\t\tself.x = x\n","\t\tself.y = y\n","\t\t\n","\tdef __len__(self):\n","\t\treturn len(self.x)\n","\t\t\n","\tdef __getitem__(self, idx):\n","\t\treturn self.x[idx], self.y[idx]\n","\t\t\n","\n","class Execute:\n","\t'''\n","\tClass for execution. Initializes the preprocessing as well as the \n","\tTweet Classifier model\n","\t'''\n","\n","\tdef __init__(self, args, device):\n","\t\tself.__init_data__(args)\n","\t\t\n","\t\tself.args = args\n","\t\tself.batch_size = args.batch_size\n","\t\tself.device=device\n","\t\tself.model = TweetClassifier(args)\n","\t\tself.model.to(self.device)\n","\t\tself.CEL=nn.NLLLoss()\n","\t\t\n","\tdef __init_data__(self, args):\n","\t\t'''\n","\t\tInitialize preprocessing from raw dataset to dataset split into training and testing\n","\t\tTraining and test datasets are index strings that refer to tokens\n","\t\t'''\n","\t\tself.preprocessing = Preprocessing(args)\n","\t\tself.preprocessing.load_data()\n","\t\tself.preprocessing.prepare_tokens()\n","\n","\t\traw_x_train = self.preprocessing.x_train\n","\t\traw_x_test = self.preprocessing.x_test\n","\t\t\n","\t\tself.y_train = self.preprocessing.y_train\n","\t\tself.y_test = self.preprocessing.y_test\n","\n","\t\tself.x_train = self.preprocessing.sequence_to_token(raw_x_train)\n","\t\tself.x_test = self.preprocessing.sequence_to_token(raw_x_test)\n","        \n","\t\t#------------fine tune dataset processing----------------------\n","\t\tself.preprocessingft = PreprocessingFT(args)\n","\t\tself.preprocessingft.load_data()\n","\t\tself.preprocessingft.prepare_tokens()\n","\n","\t\traw_x_finetune = self.preprocessingft.x_train\n","\t\traw_x_fttest = self.preprocessingft.x_test\n","\t\t\n","\t\tself.y_finetune = self.preprocessingft.y_train\n","\t\tself.y_fttest = self.preprocessingft.y_test\n","\n","\t\tself.x_finetune = self.preprocessingft.sequence_to_token(raw_x_finetune)\n","\t\tself.x_fttest = self.preprocessingft.sequence_to_token(raw_x_fttest)\n","\t\t\n","\tdef train(self):\n","\t\t\n","\t\ttraining_set = DatasetMaper(self.x_train, self.y_train)\n","\t\ttest_set = DatasetMaper(self.x_test, self.y_test)\n","        \n","\t\tfinetune_set = DatasetMaper(self.x_finetune, self.y_finetune)\n","\t\tfttest_set = DatasetMaper(self.x_fttest, self.y_fttest)\n","\t\t\n","\t\tself.loader_training = DataLoader(training_set, batch_size=self.batch_size)\n","\t\tself.loader_test = DataLoader(test_set)\n","        \n","\t\tself.loader_finetune = DataLoader(finetune_set, batch_size=self.batch_size)\n","\t\tself.loader_fttest = DataLoader(fttest_set)\n","\t\t\n","\t\t#optimizer = optim.RMSprop(self.model.parameters(), lr=args.learning_rate)\n","\t\toptimizer = optim.Adam(self.model.parameters(), lr=args.learning_rate)\n","\t\tfor epoch in range(args.epochs):\n","\t\t\t\n","\t\t\tpredictions = []\n","\t\t\t\n","\t\t\tself.model.train()\n","\t\t\t\n","\t\t\tfor x_batch, y_batch in self.loader_training:\n","\t\t\t\t\n","\t\t\t\tx = x_batch.type(torch.LongTensor)\n","\t\t\t\t#x.to(self.device)\n","\t\t\t\tx=torch.tensor(x,device=self.device)\n","\t\t\t\t#print(\"x device--->\",x.device)\n","\t\t\t\t#print(\"model device--->\",next(self.model.parameters()).is_cuda)\n","\t\t\t\t#for m in self.model.parameters():\n","\t\t\t\t\t#print(m.device) #return cuda:0\n","\t\t\t\t#y = y_batch.type(torch.FloatTensor)\n","\t\t\t\ty = y_batch.type(torch.LongTensor)\n","\t\t\t\ty=torch.tensor(y,device=self.device)\n","\t\t\t\t\n","\t\t\t\ty_pred = self.model(x)\n","\t\t\t\t#y = y.unsqueeze(1)\n","\t\t\t\t#y = y.type(torch.LongTensor)\n","\t\t\t\t#loss = F.binary_cross_entropy(y_pred, y)\n","\t\t\t\t#print(\"hjh check shape----->\",y_pred.shape,y.shape)\n","\t\t\t\tloss = self.CEL(y_pred, y)\n","\t\t\t\t\n","\t\t\t\toptimizer.zero_grad()\n","\t\t\t\t\n","\t\t\t\tloss.backward()\n","\t\t\t\t\n","\t\t\t\toptimizer.step()\n","\t\t\t\t#torch.argmax(y_pred,dim=-1)\n","\t\t\t\t#predictions += list(y_pred.squeeze().detach().numpy())\n","\t\t\t\tpredictions += list(torch.argmax(y_pred,dim=-1).cpu().detach().numpy())\n","\t\t\t\t#break\n","\t\t\t\n","\t\t\ttest_predictions = self.evaluation('train')\n","\t\t\t\n","\t\t\ttrain_accuary = self.calculate_accuray(self.y_train, predictions)\n","\t\t\ttest_accuracy = self.calculate_accuray(self.y_test, test_predictions)\n","\t\t\t\n","\t\t\tprint(\"Epoch: %d, loss: %.5f, Train accuracy: %.5f, Test accuracy: %.5f\" % (epoch+1, loss.item(), train_accuary, test_accuracy))\n","\t\t\t\n","\t\t\t\n","\t\t#----------------------fine tune and test---------------------------\n","\t\tfor epoch in range(20):\n","\t\t\t\n","\t\t\tpredictions = []\n","\t\t\t\n","\t\t\tself.model.train()\n","\t\t\t\n","\t\t\tfor x_batch, y_batch in self.loader_finetune:\n","\t\t\t\t\n","\t\t\t\tx = x_batch.type(torch.LongTensor)\n","\t\t\t\tx=torch.tensor(x,device=self.device)\n","\t\t\t\ty = y_batch.type(torch.LongTensor)\n","\t\t\t\ty=torch.tensor(y,device=self.device)\n","\t\t\t\t\n","\t\t\t\ty_pred = self.model(x)\n","\t\t\t\tloss = self.CEL(y_pred, y)\n","\t\t\t\t\n","\t\t\t\toptimizer.zero_grad()\n","\t\t\t\t\n","\t\t\t\tloss.backward()\n","\t\t\t\t\n","\t\t\t\toptimizer.step()\n","\t\t\t\tpredictions += list(torch.argmax(y_pred,dim=-1).cpu().detach().numpy())\n","\t\t\t\n","\t\t\t#test_predictions = self.evaluation('test')\n","\t\t\ttest_predictions, test_all_pred = self.evaluation('test')\n","\t\t\t\n","\t\t\ttrain_accuary = self.calculate_accuray(self.y_finetune, predictions)\n","\t\t\ttest_accuracy = self.calculate_accuray(self.y_fttest, test_predictions)\n","\t\t\t\n","\t\t\tprint(\"Epoch: %d, loss: %.5f, Train accuracy: %.5f, Test accuracy: %.5f\" % (epoch+1, loss.item(), train_accuary, test_accuracy))\n","\t\t\t\n","\t\t\tif((epoch==4 or epoch==9 or epoch==14 or epoch==19)==False):\n","\t\t\t\tcontinue\n","\t\t\t\n","\t\t\tsave_path=\"/kaggle/working/baselineLSTM_cpu_epoch_\"+str(epoch+1)+\"_test_res.csv\"\n","\t\t\tn=len(self.y_fttest)\n","\t\t\trecord=[]\n","\t\t\tfor j in range(0,n):\n","\t\t\t\ttmp={\"index\":j, \"label\":self.y_fttest[j], \"prediction\":test_predictions[j], \"all_pred\":test_all_pred[j]}\n","\t\t\t\trecord.append(tmp)\n","\n","\t\t\twith open(save_path, 'w', newline='') as csvfile:\n","\t\t\t\tfieldnames = ['index', 'label','prediction','all_pred']\n","\t\t\t\twriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","\t\t\t\twriter.writeheader()\n","\t\t\t\twriter.writerows(record)\n","\t\t\tprint(save_path)\n","            \n","\tdef evaluation(self,mode):\n","\n","\t\tpredictions = []\n","\t\tself.model.eval()\n","\t\tif(mode=='train'):\n","\t\t\tloader=self.loader_test\n","\t\telif(mode=='test'):\n","\t\t\tloader=self.loader_fttest\n","\t\twith torch.no_grad():\n","\t\t\t#for x_batch, y_batch in self.loader_test:\n","\t\t\tall_pred=[]#add\n","\t\t\tfor x_batch, y_batch in loader:\n","\t\t\t\tx = x_batch.type(torch.LongTensor)\n","\t\t\t\tx=torch.tensor(x,device=self.device)\n","\t\t\t\t#y = y_batch.type(torch.FloatTensor)\n","\t\t\t\ty = y_batch.type(torch.LongTensor)\n","\t\t\t\ty=torch.tensor(y,device=self.device)\n","\t\t\t\t\n","\t\t\t\ty_pred = self.model(x)\n","\t\t\t\tall_pred += list(y_pred.cpu().detach().numpy())#add\n","\t\t\t\tpredictions += list(torch.argmax(y_pred,dim=-1).cpu().detach().numpy())\n","\t\t\t\t\n","\t\tif(mode=='train'):\n","\t\t\treturn predictions\n","\t\telif(mode=='test'):\n","\t\t\treturn predictions,all_pred\n","\t\t\t\n","\t@staticmethod\n","\tdef calculate_accuray(grand_truth, predictions):\n","\t\ttrue_positives = 0\n","\t\ttrue_negatives = 0\n","\t\t#print(len(grand_truth),len(predictions))\n","\t\t#print(grand_truth)\n","\t\t#print(predictions)\n","\t\tfor true, pred in zip(grand_truth, predictions):\n","\t\t\t#if (pred > 0.5) and (true == 1):\n","\t\t\tif(pred==true):\n","\t\t\t\ttrue_positives += 1\n","\t\t\t#elif (pred < 0.5) and (true == 0):\n","\t\t\t#else:\n","\t\t\t\t#true_negatives += 1\n","\t\t\t#else:\n","\t\t\t\t#pass\n","\t\t\t\t\n","\t\treturn (true_positives+true_negatives) / len(grand_truth)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:31:39.685020Z","iopub.status.busy":"2023-05-16T03:31:39.684077Z","iopub.status.idle":"2023-05-16T03:33:22.075130Z","shell.execute_reply":"2023-05-16T03:33:22.073950Z","shell.execute_reply.started":"2023-05-16T03:31:39.684967Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, loss: 1.38575, Train accuracy: 0.26491, Test accuracy: 0.37483\n","Epoch: 2, loss: 1.36121, Train accuracy: 0.34517, Test accuracy: 0.46335\n","Epoch: 3, loss: 1.34569, Train accuracy: 0.40959, Test accuracy: 0.47994\n","Epoch: 4, loss: 1.34163, Train accuracy: 0.44772, Test accuracy: 0.47994\n","Epoch: 5, loss: 1.32444, Train accuracy: 0.46956, Test accuracy: 0.47994\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:154: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, loss: 1.36714, Train accuracy: 0.31963, Test accuracy: 0.39439\n","Epoch: 2, loss: 1.35831, Train accuracy: 0.31589, Test accuracy: 0.39439\n","Epoch: 3, loss: 1.36375, Train accuracy: 0.31402, Test accuracy: 0.39439\n","Epoch: 4, loss: 1.37708, Train accuracy: 0.32710, Test accuracy: 0.39439\n","Epoch: 5, loss: 1.37859, Train accuracy: 0.30841, Test accuracy: 0.39439\n","/kaggle/working/baselineLSTM_cpu_epoch_5_test_res.csv\n","Epoch: 6, loss: 1.35470, Train accuracy: 0.29533, Test accuracy: 0.39439\n","Epoch: 7, loss: 1.36501, Train accuracy: 0.33645, Test accuracy: 0.39439\n","Epoch: 8, loss: 1.34816, Train accuracy: 0.32336, Test accuracy: 0.39439\n","Epoch: 9, loss: 1.35056, Train accuracy: 0.33832, Test accuracy: 0.39439\n","Epoch: 10, loss: 1.34927, Train accuracy: 0.32897, Test accuracy: 0.39439\n","/kaggle/working/baselineLSTM_cpu_epoch_10_test_res.csv\n","Epoch: 11, loss: 1.35989, Train accuracy: 0.31028, Test accuracy: 0.39439\n","Epoch: 12, loss: 1.35175, Train accuracy: 0.33271, Test accuracy: 0.39439\n","Epoch: 13, loss: 1.33726, Train accuracy: 0.32336, Test accuracy: 0.39439\n","Epoch: 14, loss: 1.36324, Train accuracy: 0.33645, Test accuracy: 0.39439\n","Epoch: 15, loss: 1.34894, Train accuracy: 0.33271, Test accuracy: 0.39439\n","/kaggle/working/baselineLSTM_cpu_epoch_15_test_res.csv\n","Epoch: 16, loss: 1.34787, Train accuracy: 0.31589, Test accuracy: 0.39439\n","Epoch: 17, loss: 1.33913, Train accuracy: 0.33645, Test accuracy: 0.39439\n","Epoch: 18, loss: 1.34984, Train accuracy: 0.32523, Test accuracy: 0.39439\n","Epoch: 19, loss: 1.33819, Train accuracy: 0.34019, Test accuracy: 0.39439\n","Epoch: 20, loss: 1.34199, Train accuracy: 0.33645, Test accuracy: 0.39439\n","/kaggle/working/baselineLSTM_cpu_epoch_20_test_res.csv\n"]}],"source":["args = MyArgs()\n","\n","# specify GPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","#device = 'cpu'\n","print(device)\n","\n","execute = Execute(args,device)\n","execute.train()\n","\n","#from keras_preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T03:04:41.466344Z","iopub.status.busy":"2023-05-16T03:04:41.465901Z","iopub.status.idle":"2023-05-16T03:04:54.467607Z","shell.execute_reply":"2023-05-16T03:04:54.466191Z","shell.execute_reply.started":"2023-05-16T03:04:41.466305Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras_preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_preprocessing) (1.21.6)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras_preprocessing) (1.16.0)\n","Installing collected packages: keras_preprocessing\n","Successfully installed keras_preprocessing-1.1.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install keras_preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
